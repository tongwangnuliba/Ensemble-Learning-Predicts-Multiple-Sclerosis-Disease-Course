{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas_profiling\n",
    "import imblearn\n",
    "import openpyxl\n",
    "import time\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# only remain the records with on missing value on edss  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of features with time appended\n",
    "# e.g. create_list('race', 5) will create a list of 5 elements [race_0, race_6, race_12, race_18, race_24]\n",
    "def create_list(feat, num=4):\n",
    "    list = []\n",
    "    for i in range(1,num):\n",
    "        list.append(feat + \"_\" + str(i))\n",
    "    return list\n",
    "\n",
    "# interpolated Nan values of edsses\n",
    "# numYear to interpolate (5 or 10 years)\n",
    "def interpolate_edss(df, numYear):\n",
    "    edss_y=create_list('EDSS', 2*(numYear+2))#这个地方看看怎么改\n",
    "    interpolated_edss = df[edss_y].interpolate()\n",
    "    interpolated_df = df.copy()\n",
    "    interpolated_df[edss_y] = interpolated_edss\n",
    "    return interpolated_edss, interpolated_df\n",
    "raw_data = pd.read_csv('newone.csv', index_col=None, na_values=['NA'])\n",
    "df=raw_data.copy()\n",
    "# index of rows having nan values at column EDSS_60\n",
    "index_60 = raw_data['EDSS_6'].index[raw_data['EDSS_6'].apply(np.isnan)].tolist()\n",
    "ddf=df.drop(index_60)\n",
    "index_1 = ddf['EDSS_1'].index[ddf['EDSS_1'].apply(np.isnan)].tolist()\n",
    "index_2 = ddf['EDSS_2'].index[ddf['EDSS_2'].apply(np.isnan)].tolist()\n",
    "index_3 = ddf['EDSS_3'].index[ddf['EDSS_3'].apply(np.isnan)].tolist()\n",
    "drpset = set(index_1).intersection(index_2).intersection(index_3)\n",
    "ddf = ddf.drop(drpset)\n",
    "ddf.to_csv('newdata400.csv', na_rep = 'NA', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process the all variables and add differences between differnt timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define functions\n",
    "def get_idx(hdf, feat, switch=True):\n",
    "    df2 = hdf[feat].copy()\n",
    "    # replace X with np.nan\n",
    "    if switch:\n",
    "        df2.replace({'X' : np.nan}, inplace = True)\n",
    "        df2.replace({'x' : np.nan}, inplace = True)\n",
    "    # drop rows having all Nan values\n",
    "    idx2 = (df2.dropna(axis=0, how='all').index.tolist())\n",
    "    df2 = df2.astype(float)\n",
    "    dfr = df2.loc[idx2].interpolate(axis=1, limit_direction='both')\n",
    "    return dfr\n",
    "\n",
    "# function to binarize a longitudinal dataframe\n",
    "# transpose, flatten, catergorize, factorize, reshape back to matrix\n",
    "def cat_factorize(df, bins=5):\n",
    "    flatten = df.values.T.reshape(-1,)\n",
    "    tranform = pd.factorize(pd.cut(flatten, bins),sort=True)[0]\n",
    "    toMatrix = tranform.reshape(df.shape[1], df.shape[0]).T\n",
    "    return pd.DataFrame(data=toMatrix, columns=df.columns)\n",
    "\n",
    "def get_idx_N(hdf, feat, repl, switch=True):\n",
    "    df2 = hdf[feat].copy()\n",
    "    # replace X with np.nan\n",
    "    if switch:\n",
    "        df2.replace(repl, inplace = True)\n",
    "    # drop rows having all Nan values\n",
    "    idx2 = (df2.dropna(axis=0, how='all').index.tolist())\n",
    "    dfr = df2.loc[idx2].interpolate(axis=1, limit_direction='both')\n",
    "    return dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a group for each temporal feature\n",
    "Pyramidal = create_list(\"Pyramidal\")\n",
    "Cerebellar = create_list(\"Cerebellar\")\n",
    "Brainstem = create_list(\"Brainstem\")\n",
    "Bowel_bladder_raw = create_list(\"Bowel_bladder_raw\")\n",
    "MENTAL_FUNCTION = create_list(\"MENTAL_FUNCTION\")\n",
    "Visual_raw=create_list(\"Visual_raw\")\n",
    "Sensory=create_list(\"Sensory\")\n",
    "Timed_Walk_Trial_1_time=create_list(\"Timed_Walk_Trial_1_time\")\n",
    "Timed_Walk_Trial_2_time=create_list(\"Timed_Walk_Trial_2_time\")\n",
    "LESION_VOLUME=create_list(\"LESION_VOLUME\")\n",
    "Brain_white_matter_volume=create_list(\"Brain_white_matter_volume\")\n",
    "Brain_grey_matter_volume=create_list(\"Brain_grey_matter_volume\")\n",
    "Brain_volume=create_list(\"Brain_volume\")\n",
    "Cortical_grey_matter_volume=create_list(\"Cortical_grey_matter_volume\")\n",
    "Ventricular_CSF_volume=create_list(\"Ventricular_CSF_volume\")\n",
    "TOTAL_GD=create_list(\"TOTAL_GD\")\n",
    "attackprev180days=create_list(\"attackprev180days\")\n",
    "attackprev2y=create_list(\"attackprev2y\")\n",
    "ontreat=create_list(\"ontreat\")\n",
    "timeontreat_days=create_list(\"timeontreat_days\")\n",
    "EDSS=create_list(\"EDSS\")\n",
    "\n",
    "#process the category data\n",
    "# continuous features with sensory function\n",
    "dmgr_cols = [ 'SEX', 'RACE_DESC', 'ETHNICITY_DESC']\n",
    "age_col = ['visit_age_1']\n",
    "\n",
    "file_path = \"newdata400.csv\"\n",
    "whole_df = pd.read_csv(file_path, index_col=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add the differences\n",
    "hdf = whole_df.copy()\n",
    "df1 = get_idx(hdf, Pyramidal,True  )    \n",
    "df2 = get_idx(hdf, Cerebellar,)    \n",
    "df3 = get_idx(hdf, Brainstem, True )    \n",
    "df5 = get_idx(hdf, Cerebellar, )    \n",
    "df6 = get_idx(hdf, Bowel_bladder_raw, False) \n",
    "df8 = get_idx(hdf, MENTAL_FUNCTION, False)\n",
    "df11= get_idx(hdf, Sensory,True  )  \n",
    "df12 = get_idx(hdf, Timed_Walk_Trial_2_time,False  )  \n",
    "df13 = get_idx(hdf, Brain_white_matter_volume,False  )  \n",
    "df14 = get_idx(hdf, Brain_grey_matter_volume,False  )  \n",
    "df15 = get_idx(hdf, Cortical_grey_matter_volume,False  )  \n",
    "df16 = get_idx(hdf, Cortical_grey_matter_volume,False  )  \n",
    "df17 = get_idx(hdf, Ventricular_CSF_volume,False  )  \n",
    "df18 = get_idx(hdf, TOTAL_GD,False  )  \n",
    "df19 = get_idx(hdf, attackprev180days,False  )  \n",
    "df20 = get_idx(hdf, attackprev2y,False  )  \n",
    "df21 = get_idx(hdf, ontreat,False  )  \n",
    "df22 = get_idx(hdf, timeontreat_days,False  )  \n",
    "for df in (df1,df2,df3,df5,df6,df8):\n",
    "    df[df.columns[0][:-2]+'_' +'difference1']=df.iloc[:,1]-df.iloc[:,0]\n",
    "    df[df.columns[0][:-2]+'_' 'difference2']=df.iloc[:,2]-df.iloc[:,1]\n",
    "cclist = []\n",
    "for df in [df1, df2, df3, df5, df6,  df8]:\n",
    "    cclist.append(df)\n",
    "# dataframe of all functions\n",
    "sfdf = pd.concat(cclist, axis=1)\n",
    "df9_edss = get_idx(hdf, EDSS, False)\n",
    "df9_edss['edss_difference1']=df9_edss.iloc[:,1]-df9_edss.iloc[:,0]\n",
    "df9_edss['edss_difference2']=df9_edss.iloc[:,2]-df9_edss.iloc[:,1]\n",
    "age_col_cf = cat_factorize(hdf[age_col], 3)\n",
    "for df in (df11, df12, df13, df14, df15, df16, df17, df18, df19, df20, df21, df22):\n",
    "    df[df.columns[0][:-2]+'_'+'difference1']=df.iloc[:,1]-df.iloc[:,0]\n",
    "    df[df.columns[0][:-2]+'_'+'difference2']=df.iloc[:,2]-df.iloc[:,1]\n",
    "bblist = []\n",
    "for df in [df11, df12, df13, df14, df15, df16, df17, df18, df19, df20, df21, df22]:\n",
    "    bblist.append(df)\n",
    "    # dataframe of all functions\n",
    "bbdf = pd.concat(bblist, axis=1)\n",
    "\n",
    "ttlist = []\n",
    "for df in [hdf[dmgr_cols], age_col_cf, sfdf, bbdf, df9_edss]:\n",
    "    ttlist.append(df)\n",
    "ttdf = pd.concat(ttlist, axis=1)\n",
    "idx60 = list(ddf.index)\n",
    "ppdts = ttdf.loc[idx60]\n",
    "labels = hdf.loc[idx60]['EDSS_6']-hdf.loc[idx60]['EDSS_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save the processed independent variables and lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = 1.5\n",
    "saved_labels = labels.copy()\n",
    "saved_labels[labels>=diff] = 1\n",
    "saved_labels[labels<diff] = 0\n",
    "pd.DataFrame(saved_labels, columns=['labels']).astype(int).to_csv('Ys.csv', na_rep = 'NA', index=False, columns=['labels'], encoding='utf-8')\n",
    "new_X_fn = ppdts.fillna(-1)\n",
    "dm_X = pd.get_dummies(new_X_fn)\n",
    "dm_X.to_csv('new_D1_X.csv', na_rep = 'NA', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
